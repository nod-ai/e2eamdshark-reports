## Passing Summary

**TOTAL TESTS = 236**
|Stage|# Passing|% of Total|% of Attempted|
|--|--|--|--|
| Setup | 0 | 0.0% | 0.0% |
| IREE Compilation | 0 | 0.0% | 0.0% |
| Gold Inference | 0 | 0.0% | 0.0% |
| IREE Inference Invocation | 0 | 0.0% | 0.0% |
| Inference Comparison (PASS) | 0 | 0.0% | 0.0% |
## Fail Summary

**TOTAL TESTS = 236**
|Stage|# Failed at Stage|% of Total|
|--|--|--|
| Setup | 236 | 100.0% |
| IREE Compilation | 0 | 0.0% |
| Gold Inference | 0 | 0.0% |
| IREE Inference Invocation | 0 | 0.0% |
| Inference Comparison | 0 | 0.0% |
## Test Run Detail
Test was run with the following arguments:
Namespace(sources=['./e2eamdshark-reports/ci_reports_rocm_nlp-shard1_unique_onnx_json/nlp-shard1_unique.json', './e2eamdshark-reports/ci_reports_rocm_nlp-shard2_unique_onnx_json/nlp-shard2_unique.json', './e2eamdshark-reports/ci_reports_rocm_nlp-shard3_unique_onnx_json/nlp-shard3_unique.json'], output='./e2eamdshark-reports/nlp_unique.json', report=True, report_file='./e2eamdshark-reports/nlp_unique.md')

| Test | Exit Status | Mean Benchmark Time (ms) | Notes |
|--|--|--|--|
| model--125M_GPTneo_reward_base--Myashka | setup | None | |
| model--BART--Shubham09 | setup | None | |
| model--BERT_summary--Shobhank-iiitdwd | setup | None | |
| model--Bartlarge--Shubham09 | setup | None | |
| model--BioM-ELECTRA-Base-SQuAD2--sultan | setup | None | |
| model--CodeGen-350M-Multi--xhyi | setup | None | |
| model--Electra-Large-SQUADV2--titanbot | setup | None | |
| model--EstBERT128_sentiment--tartuNLP | setup | None | |
| model--FinancialBERT-Sentiment-Analysis--ahmedrachid | setup | None | |
| model--GPyT--Sentdex | setup | None | |
| model--IMDB_ELECTRA_5E--pig4431 | setup | None | |
| model--Jasmine-350M--UBC-NLP | setup | None | |
| model--M-TurQA-convbert-base-turkish-cased-finetuned-toqad-aug--meetyildiz | setup | None | |
| model--MEDIA_NLU-flaubert_oral_mixed--vpelloin | setup | None | |
| model--MTL-distilbert-base-uncased-squad--jgammack | setup | None | |
| model--Microllama_Char_200k_step--Corianas | setup | None | |
| model--MiniLM-L12-H384-uncased-squad--haritzpuerto | setup | None | |
| model--QAmembert--CATIE-AQ | setup | None | |
| model--SAE-roberta-base-squad--jgammack | setup | None | |
| model--SEAD-L-6_H-384_A-12-wnli--course5i | setup | None | |
| model--TinyBERT_General_4L_312D-squad--haritzpuerto | setup | None | |
| model--TinyMistral-248M-v2-cleaner--M4-ai | setup | None | |
| model--TinyStories-1Layer-21M--roneneldan | setup | None | |
| model--TinyStories-1M--roneneldan | setup | None | |
| model--TinyStories-2Layers-33M--roneneldan | setup | None | |
| model--TinyStories-33M--roneneldan | setup | None | |
| model--TinyStories-3M--roneneldan | setup | None | |
| model--TinyStories-8M--roneneldan | setup | None | |
| model--Translation--shed-e | setup | None | |
| model--XLMRoberta-Alexa-Intents-NER-NLU--qanastek | setup | None | |
| model--XLMRobertaLongForQuestionAnswering-base-squad2-512-4096--sadaqabdo | setup | None | |
| model--YuisekinAI-mistral-0.7B--yuiseki | setup | None | |
| model--albert-base-v2-finetuned-ner--ArBert | setup | None | |
| model--albert-base-v2-finetuned-squad--Firat | setup | None | |
| model--albert-large-v2_ner_conll2003--Gladiator | setup | None | |
| model--albert-large-v2_ner_wikiann--Gladiator | setup | None | |
| model--albert-large-v2_squad--Palak | setup | None | |
| model--albert-xxl-v2-finetuned-squad--anas-awadalla | setup | None | |
| model--bart-CaPE-xsum--praf-choub | setup | None | |
| model--bart-base-booksum--KamilAin | setup | None | |
| model--bart-base-few-shot-k-1024-finetuned-squad-seed-2--anas-awadalla | setup | None | |
| model--bart-large-finetuned-squadv1--valhalla | setup | None | |
| model--bengali_language_NER--Suchandra | setup | None | |
| model--bert-base-cased-cefr--LordCoffee | setup | None | |
| model--bert-base-finetuned-nli--Jihyun22 | setup | None | |
| model--bert-base-multilingual-uncased-finetuned-squad--Martin97Bozic | setup | None | |
| model--bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3--husnu | setup | None | |
| model--bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3TQUAD2-finetuned_lr-2e-05_epochs-1--husnu | setup | None | |
| model--bert-base-tweetner7-2021--tner | setup | None | |
| model--bert-base-uncased-imdb--fabriceyhc | setup | None | |
| model--bert-base-uncased-squad-v1--csarron | setup | None | |
| model--bert-cased-ner-fcit499--Ahmed87 | setup | None | |
| model--bert-engonly-sentiment-test--SiddharthaM | setup | None | |
| model--bert-finetuned-chunking--ish97 | setup | None | |
| model--bert-finetuned-imdb--Wakaka | setup | None | |
| model--bert-finetuned-ner--jatinshah | setup | None | |
| model--bert-finetuned-ner_offres--bileldh | setup | None | |
| model--bert-finetuned-squad--Aaroosh | setup | None | |
| model--bert-german-ler--elenanereiss | setup | None | |
| model--bert-german-ner--lunesco | setup | None | |
| model--bert-imdb-1hidden--lannelin | setup | None | |
| model--bert-l-squadv1.1-sl256--vuiseng9 | setup | None | |
| model--bert-large-NER--51la5 | setup | None | |
| model--bert-large-uncased-en-ner--n6ai | setup | None | |
| model--bert-medium-pretrained-finetuned-squad--anas-awadalla | setup | None | |
| model--bert-mini-finetuned-squad--anas-awadalla | setup | None | |
| model--biobert-base-cased-v1.2-bc2gm-ner--chintagunta85 | setup | None | |
| model--bleurt-tiny-128--Elron | setup | None | |
| model--bsc-bio-ehr-es-cantemist--PlanTL-GOB-ES | setup | None | |
| model--bsc-bio-ehr-es-pharmaconer--PlanTL-GOB-ES | setup | None | |
| model--camembert-base-fquad--illuin | setup | None | |
| model--cm_code_clippy--ncoop57 | setup | None | |
| model--deberta-italian-question-answering--osiria | setup | None | |
| model--deberta-v3-base-qa-en--LLukas22 | setup | None | |
| model--deberta-v3-base__sst2__all-train--SetFit | setup | None | |
| model--deberta-v3-large-squad2--deepset | setup | None | |
| model--deberta-v3-xsmall-squad2--nlpconnect | setup | None | |
| model--distilBERT-infoExtract--tony4194 | setup | None | |
| model--distilbart-cnn-12-3--sshleifer | setup | None | |
| model--distilbart-cnn-12-6-samsum--philschmid | setup | None | |
| model--distilbart-cnn-6-6--sshleifer | setup | None | |
| model--distilbart-xsum-1-1--sshleifer | setup | None | |
| model--distilbart-xsum-12-1--sshleifer | setup | None | |
| model--distilbart-xsum-9-6--sshleifer | setup | None | |
| model--distilbert-base-NER--51la5 | setup | None | |
| model--distilbert-base-cased-distilled-squad--distilbert | setup | None | |
| model--distilbert-base-german-cased-finetuned-ner--FabianWillner | setup | None | |
| model--distilbert-base-multilingual-cased-finetuned-squad--monakth | setup | None | |
| model--distilbert-base-uncased-finetuned-ner--dbsamu | setup | None | |
| model--distilbert-base-uncased-finetuned-squad--negfir | setup | None | |
| model--distilbert-srb-ner--Aleksandar | setup | None | |
| model--distilcamembert-base-ner--cmarkea | setup | None | |
| model--distilcamembert-base-qa--cmarkea | setup | None | |
| model--distilgpt2-sd--aabidk | setup | None | |
| model--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es--mrm8488 | setup | None | |
| model--distilroberta-base-ner-conll2003--philschmid | setup | None | |
| model--distilroberta-base-ner-wikiann--philschmid | setup | None | |
| model--distilroberta-finetuned-financial-text-classification--nickmuchi | setup | None | |
| model--dynamic_tinybert--Intel | setup | None | |
| model--electra-base-discriminator-finetuned-conll03-english--bhadresh-savani | setup | None | |
| model--electra-base-irish-cased-discriminator-v1-finetuned-ner--jimregan | setup | None | |
| model--electra-small-discriminator-finetuned-ner--dbsamu | setup | None | |
| model--electra-small-turkish-uncased-discriminator-finetuned_lr-2e-05_epochs-3--husnu | setup | None | |
| model--electra-srb-ner--Aleksandar | setup | None | |
| model--en-finetuned-squad-qa-minilmv2-32--subhasisj | setup | None | |
| model--enlm-roberta-imdb--manirai91 | setup | None | |
| model--environmental-claims--climatebert | setup | None | |
| model--finbert--ProsusAI | setup | None | |
| model--finetuned-base_mini--muhtasham | setup | None | |
| model--finetuned-base_small--muhtasham | setup | None | |
| model--finetuned-self_mlm_tiny--muhtasham | setup | None | |
| model--finetuned_distilgpt2_sst2_negation0.0001_pretrainedTrue_epochs1--jhaochenz | setup | None | |
| model--finetuned_gpt2-large_sst2_negation0.0_pretrainedFalse--yuhuizhang | setup | None | |
| model--finetuned_gpt2-medium_sst2_negation0.0001_pretrainedTrue--yuhuizhang | setup | None | |
| model--finetuned_gpt2_sst2_negation0.0001_pretrainedFalse_epochs1--yuhuizhang | setup | None | |
| model--finetuning-albert-base-v2-on-imdb--Ibrahim-Alam | setup | None | |
| model--finetuning-roberta-base-on-imdb--Ibrahim-Alam | setup | None | |
| model--finetuning-sentiment-imdb--Timothy1337 | setup | None | |
| model--finetuning-sentiment-model-3000-samples--DravenTay | setup | None | |
| model--finetuning-sentiment-model-3000-samples--DuboiJ | setup | None | |
| model--flan-t5-large-samsum--oguuzhansahin | setup | None | |
| model--flaubert-base-uncased-finetuned-cooking--nbouali | setup | None | |
| model--gemma-tiny-random--yujiepan | setup | None | |
| model--gm-ner-xlmrbase--CLTL | setup | None | |
| model--google_electra-base-discriminator_squad--Palak | setup | None | |
| model--google_electra-small-discriminator_squad--Palak | setup | None | |
| model--gpt2--openai-community | setup | None | |
| model--gpt2-alpaca-gpt4--vicgalle | setup | None | |
| model--hebrew_poetry-gpt_neo-small--Norod78 | setup | None | |
| model--ia-detection-tiny-random-gptj--arincon | setup | None | |
| model--ibert-roberta-base-finetuned-mrpc--VitaliiVrublevskyi | setup | None | |
| model--llama-160m--JackFram | setup | None | |
| model--llama-wikitext--manu | setup | None | |
| model--long-t5-tglobal-base-16384-book-summary--pszemraj | setup | None | |
| model--long-t5-tglobal-large-pubmed-3k-booksum-16384-WIP--pszemraj | setup | None | |
| model--lsg-bart-base-4096-booksum--ccdv | setup | None | |
| model--ltgbert-qa--amroadel1 | setup | None | |
| model--m2m100_418M-finetuned-kde4-en-to-pt_BR--danhsf | setup | None | |
| model--m2m100_418M-fr--Jour | setup | None | |
| model--mBERT-squad--intanm | setup | None | |
| model--mT5-base-HunSum-1--SZTAKI-HLT | setup | None | |
| model--manifestoberta-xlm-roberta-56policy-topics-sentence-2023-1-1--manifesto-project | setup | None | |
| model--marian-finetuned-kde4-cs2sv--ksaml | setup | None | |
| model--marian-finetuned-kde4-en-to-ar--anibahug | setup | None | |
| model--marian-finetuned-kde4-en-to-es--tmobaggins | setup | None | |
| model--marian-finetuned-kde4-en-to-hi--vsrinivas | setup | None | |
| model--marian-finetuned-kde4-en-to-vi--VanHoan | setup | None | |
| model--mbert-bengali-ner--sagorsarker | setup | None | |
| model--mbert-imdb--manirai91 | setup | None | |
| model--mdeberta-v3-base-squad2--sjrhuschlee | setup | None | |
| model--medium-mlm-imdb-target-imdb--muhtasham | setup | None | |
| model--megatron-gpt2-345m--robowaifudev | setup | None | |
| model--microsoft-deberta-v3-large_ner_conll2003--Gladiator | setup | None | |
| model--microsoft_deberta-base_squad--Palak | setup | None | |
| model--microsoft_deberta-large_squad--Palak | setup | None | |
| model--mobilebert-squadv2--aware-ai | setup | None | |
| model--mobilebert_cola--Alireza1044 | setup | None | |
| model--mobilebert_mnli--Alireza1044 | setup | None | |
| model--mt5-small-sum-de-en-v1--deutsche-telekom | setup | None | |
| model--my_awesome_gptj_model--anandshende | setup | None | |
| model--my_xlm-roberta-large-finetuned-conll03--BahAdoR0101 | setup | None | |
| model--nbailab-base-ner-scandi--saattrupdan | setup | None | |
| model--nd-qna--Trisert | setup | None | |
| model--ner-bert-base-cased-pt-lenerbr--pierreguillou | setup | None | |
| model--ner-bert-large-cased-pt-lenerbr--pierreguillou | setup | None | |
| model--ner_conll2003--ramybaly | setup | None | |
| model--opt-125m-finetuned-squad-assignment--Isente | setup | None | |
| model--opt-350m--facebook | setup | None | |
| model--opt-350m-wikitext2--lnair | setup | None | |
| model--opt-finetuned-squad-dataset--choohan | setup | None | |
| model--outputs--ankitkupadhyay | setup | None | |
| model--pegasus-cnn_dailymail--google | setup | None | |
| model--pegasus-large-book-summary--pszemraj | setup | None | |
| model--pegasus-large-booksum--cnicu | setup | None | |
| model--phi-2-classifier--roborovski | setup | None | |
| model--pythia-410mn-ntoxic--skrishna | setup | None | |
| model--pythia-70-m-finetuned--selinerdem | setup | None | |
| model--pythia-70m-toxicity-model--skrishna | setup | None | |
| model--query_wellformedness_score--Ashishkr | setup | None | |
| model--really-tiny-falcon-testing--fxmarty | setup | None | |
| model--reward-model-deberta-v3-large-v2--OpenAssistant | setup | None | |
| model--rm_checkpoint--Manoj120 | setup | None | |
| model--roberta-base-bne-sqac--PlanTL-GOB-ES | setup | None | |
| model--roberta-base-ca-cased-ner--projecte-aina | setup | None | |
| model--roberta-base-finetuned-mbti-0901--GItaf | setup | None | |
| model--roberta-base-finetuned-ner--dominiqueblok | setup | None | |
| model--roberta-l-squadv1.1--vuiseng9 | setup | None | |
| model--roberta-large-bne-sqac--PlanTL-GOB-ES | setup | None | |
| model--roberta-large-finetuned-ner--romainlhardy | setup | None | |
| model--roberta-large-ner-english--Jean-Baptiste | setup | None | |
| model--roberta-large-tweetner7-all--tner | setup | None | |
| model--roberta-med-small_shared-finetuned-bbc_xsum-summarization--mrm8488 | setup | None | |
| model--roberta-ner-multilingual--julian-schelb | setup | None | |
| model--roberta_large-filtered_simple-chunk-conll2003_0907_v1--mariolinml | setup | None | |
| model--roberta_qa_japanese--tsmatz | setup | None | |
| model--roberta_shared_bbc_xsum--patrickvonplaten | setup | None | |
| model--rubert-tiny-toxicity--cointegrated | setup | None | |
| model--s2t-medium-librispeech-asr--facebook | setup | None | |
| model--sberbank-rubert-base-collection3--viktoroo | setup | None | |
| model--slovakbert-ner--crabz | setup | None | |
| model--smol_llama-220M-GQA--BEE-spoke-data | setup | None | |
| model--smol_llama-81M-tied--BEE-spoke-data | setup | None | |
| model--spanbert-large-squad--anas-awadalla | setup | None | |
| model--splinter-large-few-shot-k-16-finetuned-squad-seed-0--anas-awadalla | setup | None | |
| model--splinter-large-few-shot-k-16-finetuned-squad-seed-2--anas-awadalla | setup | None | |
| model--squad_it_xxl_cased_hub1--luigisaetta | setup | None | |
| model--squeezebert-uncased-finetuned-squad--SupriyaArun | setup | None | |
| model--summarization-not-evaluated--autoevaluate | setup | None | |
| model--t5-base-fr-sum-cnndm--plguillou | setup | None | |
| model--t5-large-finetuned-xsum-cnn--sysresearch101 | setup | None | |
| model--tiny-bert-qa--srcocotero | setup | None | |
| model--tiny-gpt2--taufeeque | setup | None | |
| model--tiny-gpt2-magicprompt--pszemraj | setup | None | |
| model--tiny-random-ConvBertForQuestionAnswering--hf-tiny-model-private | setup | None | |
| model--tiny-random-FalconForCausalLM--illuin | setup | None | |
| model--tiny-random-FlaubertForQuestionAnsweringSimple--hf-tiny-model-private | setup | None | |
| model--tiny-random-FlaubertForTokenClassification--hf-tiny-model-private | setup | None | |
| model--tiny-random-GPTJForQuestionAnswering--hf-tiny-model-private | setup | None | |
| model--tiny-random-GPTNeoForSequenceClassification--hf-tiny-model-private | setup | None | |
| model--tiny-random-RoFormerForQuestionAnswering--hf-tiny-model-private | setup | None | |
| model--tiny-random-gptj-for-sequence-classification--ydshieh | setup | None | |
| model--tiny-random-llama--IlyasMoutawwakil | setup | None | |
| model--tiny-testing-falcon-alibi--fxmarty | setup | None | |
| model--twitter-roberta-base-dec2021-tweetner7-random--tner | setup | None | |
| model--twitter-roberta-base-emotion--cardiffnlp | setup | None | |
| model--wikibert-finetuned-vsmec--ThuanPhong | setup | None | |
| model--xlm-roberta-base-conll2003-ner--Yaxin | setup | None | |
| model--xlm-roberta-base-finetuned-panx-de--chaewonlee | setup | None | |
| model--xlm-roberta-base-finetuned-squad--darshana1406 | setup | None | |
| model--xlm-roberta-base-kyrgyzNER--the-cramer-project | setup | None | |
| model--xlm-roberta-imdb--manirai91 | setup | None | |
| model--xlm-roberta-large-squad2--deepset | setup | None | |
| model--xtremedistil-l6-h256-uncased-TQUAD-finetuned_lr-2e-05_epochs-3--husnu | setup | None | |
| model--xtremedistil-l6-h256-uncased-finetuned_lr-2e-05_epochs-3--husnu | setup | None | |
| model--xtremedistil-l6-h384-uncased-finetuned-squad--tachyon-11 | setup | None | |
| model--yelp_review_rating_reberta_base--Shunian | setup | None | |
